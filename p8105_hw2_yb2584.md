Homework 2
================
Yunshen Bai
2023-10-04

## Problem 0

``` r
library(tidyverse)
library(readxl)
```

## Problem 1

First, clean the data in pols-month.csv.

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

Second, clean the data in snp.csv using a similar process to the above.

``` r
snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  mutate(
    year = ifelse(year>=50, 1900+year, 2000+year), 
  )|>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

Third, tidy the unemployment data so that it can be merged with the
previous datasets.

``` r
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(y = month_df) |> 
  select(year, month, unemployment)
```

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(y = unemployment)

str(data_538)
## tibble [822 x 13] (S3: tbl_df/tbl/data.frame)
##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
##  $ month       : chr [1:822] "January" "February" "March" "April" ...
##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...
```

Notice that there are some `NA` values in the `close` and `unemployment`
variables, which indicate that the value of these variables is missing
at those locations.

Let’s talk about the 538 datasets. The `pols` data has 822 observations
and 11 variables and tells us about the party affiliation distribution
(democrat or republican) for governors and senators for a given year
from years 1947 to 2015. It also tells us whether the sitting president
was a democrat or republican. The `snp` data has 787 observations and 3
variables, ranging from years 1950 to 2015. The `unemployment` data has
816 observations and 3 variables ranging from years 1948 to 2015. In
Januarys in or after 1975 in which a democrat was president, the
**average unemployment rate was 6.57**. The average unemployment rate
over the same time period in which a republican was president was 6.47.

## Problem 2

Read and clean the Mr. Trash Wheel sheet

``` r
mr_trash_wheel=
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx",sheet = 1,skip = 1)|>
  janitor::clean_names()|>
  drop_na(dumpster)|>
  select(-x15,-x16)|>
  mutate(homes_powered=weight_tons*500/30)
```

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda

``` r
professor_trash_wheel=
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx",sheet = 2,skip = 1)|>
  janitor::clean_names()|>
  drop_na(dumpster)|>
  mutate(homes_powered=weight_tons*500/30)
```

``` r
Gwynnda=
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx",sheet = 4,skip = 1)|>
  janitor::clean_names()|>
  drop_na(dumpster)|>
  mutate(homes_powered=weight_tons*500/30)
```

Next, combine these with the Mr. Trash Wheel dataset to produce a single
tidy dataset

``` r
mr_trash_wheel=mutate(mr_trash_wheel,belongs="Mr. Trash Wheel")
professor_trash_wheel=mutate(professor_trash_wheel,belongs="Professor Trash Wheel")
Gwynnda=mutate(Gwynnda,belongs="Gwynnda")
mr_trash_wheel=mutate(mr_trash_wheel,year=as.double(year))
trash_wheel=full_join(mr_trash_wheel,professor_trash_wheel)
trash_wheel=full_join(trash_wheel,Gwynnda)
head(trash_wheel,20)
## # A tibble: 20 x 15
##    dumpster month  year date                weight_tons volume_cubic_yards
##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
## 11       11 June   2014 2014-06-11 00:00:00        3.43                 15
## 12       12 June   2014 2014-06-12 00:00:00        4.17                 19
## 13       13 June   2014 2014-06-13 00:00:00        5.13                 15
## 14       14 June   2014 2014-06-13 00:00:00        4.17                 15
## 15       15 June   2014 2014-06-19 00:00:00        3.28                 15
## 16       16 June   2014 2014-06-19 00:00:00        3.05                 15
## 17       17 June   2014 2014-06-28 00:00:00        2.49                 13
## 18       18 July   2014 2014-07-03 00:00:00        2.54                 15
## 19       19 July   2014 2014-07-07 00:00:00        2.41                 15
## 20       20 July   2014 2014-07-11 00:00:00        3.83                 18
## # i 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, belongs <chr>
```

These data includes information on the dumpter number, date of
collection, amount of total litter and litter type. The overall average
home powered is 50.1579882. The `mr_trash_wheel` data has 584
observations and 15 variables, and home powered for Mr. Trash Wheel is
53.5131279. The `professor_trash_wheel` data has 106 observations and 14
variables, and home powered for Professor Trash Wheel is 34.0031447. The
`Gwynnda` data has 155 observations and 13 variables, and home powered
for Professor Trash Wheel is 48.5645161. The total weight of trash
collected by Professor Trash Wheel is 216.26, and total number of
cigarette butts collected by Gwynnda in July of 2021 is 1.63^{4}.

## Problem 3

Import, clean, and tidy the dataset of baseline demographics

``` r
baseline=
  read_csv("./data/data_mci/data_mci/MCI_baseline.csv",skip=1)|>
  janitor::clean_names()|>
  mutate(sex=as.factor(sex),apoe4=as.factor(apoe4))
  
```

In import process, we read the data and set sex and apoe4 as factor
variable. `baseline` has 483 observations and 6 variables.In this study,
483 participants were recruited, and 97 of them developed MCI. The
average baseline age is 65.0467909. The proportion of women in the study
are APOE4 carriers is 0.2985782

``` r
amyloid=
  read_csv("./data/data_mci/data_mci/mci_amyloid.csv",skip=1)|>
  janitor::clean_names()|>
  pivot_longer(time_2:time_8,names_to = "time",values_to = "ratio")
```

In import process, we read the data and clean the variable
names.`amyloid` has 1948 observations and 4 variables.

To check whether some participants appear in only the `baseline` or
`amyloid` datasets, I will check whether the id in `baseline` and id in
`amyloid` are same.

``` r
sum(baseline$id %in% amyloid$study_id) == length(baseline$id %in% amyloid$study_id)
## [1] FALSE
sum(amyloid$study_id %in% baseline$id) == length(amyloid$study_id %in% baseline$id)
## [1] FALSE
```

From the result, id in `baseline` and id in `amyloid` are not same.
There are some participants appear in only the `baseline` or `amyloid`
datasets.

Next, combine the demographic and biomarker datasets so that only
participants who appear in both datasets are retained.

``` r
data=inner_join(baseline,amyloid,join_by(id==study_id))
```

From the result, the new dataset has 1900 observations and 9 variables.
The average age of the new dataset is 65.0658947, and 0.1978947
proportion of them developed MCI.

Export the result as a CSV to data directory.

``` r
write_csv(data,"./data/baseline_amyloid_combined.csv")
```
